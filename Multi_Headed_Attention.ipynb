{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Head Attn"
      ],
      "metadata": {
        "id": "YeTJn7cC-a2q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDCwdbq5-WKv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 4 # usually maxm sequence length in the batch\n",
        "batch_size = 1\n",
        "input_dim = 512 # vector dimension of every word that goes into attention unit\n",
        "d_model = 512 # output from the model\n",
        "x = torch.randn((batch_size, sequence_length, input_dim)) # randomly sampled input not creating position encoding right now , it will have dimension = [1, 4, 512]"
      ],
      "metadata": {
        "id": "8Mkk-_58-oqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqQHsz8V_f8o",
        "outputId": "a9a7bee4-1efa-452f-b21f-001b6a627918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x is something which will be there in multi-headed attention unit\n",
        "qkv_layer = nn.Linear(input_dim, 3*d_model) # this will give q, k and v vector for all the 8 attention heads (3 * d_model), which will be separated later on, here 3 is multiplied as we have 3 vectors q,k and v."
      ],
      "metadata": {
        "id": "szAdxUIX_hYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qkv = qkv_layer(x)"
      ],
      "metadata": {
        "id": "KAvoUEDzAAFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qkv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO6fozXlADsh",
        "outputId": "2fa5b771-e264-4ca5-f37b-9d017eefd471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 1536])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here it's 1 batch, 4 words and each word vector is 1536 in size from which I will separte out 8 heads q,k and v."
      ],
      "metadata": {
        "id": "o88V1o8rALQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_val = torch.histc(qkv, bins=200, min=-3, max=3)\n",
        "x_val = np.arange(-1, 1, 0.01) * 3\n",
        "\n",
        "plt.bar(x_val, y_val, align='center', color='green')\n",
        "plt.title('qkv_distribution')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "XkQS6CWHAF14",
        "outputId": "f4bda821-bba4-43b2-e587-ad01f88f1cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'qkv_distribution')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Values are sampled from random distribution"
      ],
      "metadata": {
        "id": "KenlJrmVA8bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now coming to multi-headed attention\n",
        "num_heads = 8\n",
        "head_dim = d_model//num_heads # 8 attention head so each attention head will have dimension 512/8 = 64\n",
        "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3*head_dim) # break down the last dimension into product of (number of heads , 3*head_dim) 3 multiplied for q,k and v"
      ],
      "metadata": {
        "id": "WVuTK2EbA2dL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qkv.shape #"
      ],
      "metadata": {
        "id": "dh72ODRGBm5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3317cc5-e3aa-4216-a57d-4e8419c25f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 8, 192])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape the qkv by switching it to [batch_size, n_heads, seq_length, 64*3=192]\n",
        "qkv = qkv.permute(0,2,1,3)"
      ],
      "metadata": {
        "id": "0HuxXMtS3JUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we will take out q, k and v for each head by breaking down it's last dimension\n",
        "q, k, v = qkv.chunk(3, dim=-1)\n",
        "q.shape, k.shape, v.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkmF709p36YZ",
        "outputId": "d0022f01-a3ef-417a-e2fd-bcc1e477d590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 8, 4, 64]),\n",
              " torch.Size([1, 8, 4, 64]),\n",
              " torch.Size([1, 8, 4, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each q , k and v vectors are for all 8 attention heads."
      ],
      "metadata": {
        "id": "5P9mlJOG4Kky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we will perform self attention for multiple heads\n",
        "# For single head it's softmax(q k.T/ sqrt(d_k=64 here) + M=masking)\n",
        "# newV = attention_score . V\n",
        "import math\n",
        "d_k = q.size()[-1] # it will be 64\n",
        "scaled_attention = torch.matmul(q, k.transpose(-2, -1))/ math.sqrt(d_k)\n",
        "scaled_attention.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UalN5bT4JvD",
        "outputId": "0dfcf50f-a5dd-4ad1-df02-0f9b1a01bcf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So here we got for 8 heads, 4x4 attention matrix\n",
        "Now why we used transpose and not simple k.T because k is a tensor of multidimension and not simply a matrix"
      ],
      "metadata": {
        "id": "HDtil7Nc5g9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# masking in encoder we don't require masking but for decoder we require masking\n",
        "# we will create the mask same as scaled attention shape 1,8,4,4\n",
        "mask = torch.full(scaled_attention.size(), float('-inf'))\n",
        "mask = torch.triu(mask, diagonal=1) # take this mask and make triangualr matrix  and leave the value everything above the diagonal as same, diagonal=1 describes how many positions above the diagonal we want to keep the same value.\n",
        "mask[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOP1j_eG5cQM",
        "outputId": "39e0e151-9735-4d18-9698-5c76d056af5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., -inf, -inf, -inf],\n",
              "        [0., 0., -inf, -inf],\n",
              "        [0., 0., 0., -inf],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(scaled_attention + mask)[0][0] # this is for basically 1 head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQwJPeib6Uy5",
        "outputId": "e8fd7353-945d-4e38-88a0-4bc17481ce68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2742,    -inf,    -inf,    -inf],\n",
              "        [-0.1151, -0.3439,    -inf,    -inf],\n",
              "        [-0.4256,  0.6179,  0.1730,    -inf],\n",
              "        [-0.4276,  0.3121,  0.3044, -0.4874]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_attention += mask # when we apply softmax these negative inf values will become 0"
      ],
      "metadata": {
        "id": "AcdOekUz68Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_scores = F.softmax(scaled_attention, dim = -1)"
      ],
      "metadata": {
        "id": "EsRvLvbh6_eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using this attention score we will calculate new value\n",
        "values = torch.matmul(attention_scores, v)\n",
        "values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljnJQMUq7RH2",
        "outputId": "e8a5905d-0cf9-4018-8eff-33c8a6881715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now this value score will have much richer representation of each word"
      ],
      "metadata": {
        "id": "ma69xrZA7h4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to do the same"
      ],
      "metadata": {
        "id": "ERVQN1Ut83lT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def scaled_dot_attention(q, k, v, mask=None):\n",
        "  d_k = q.size()[-1]\n",
        "  scaled_attention = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
        "  if mask is not None:\n",
        "    scaled_attention += mask\n",
        "\n",
        "  attention_scores = F.softmax(scaled_attention, dim = -1)\n",
        "  values = torch.matmul(attention_scores, v)\n",
        "  return values, attention_scores"
      ],
      "metadata": {
        "id": "DRXxJgkq7XdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values, attention = scaled_dot_attention(q, k, v, mask=None)"
      ],
      "metadata": {
        "id": "4LNjrOS89hJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7PfMLal-J45",
        "outputId": "95c82b56-31bc-4688-d8c0-46f2d3793315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8eh43ld-K-u",
        "outputId": "a1909d37-28a0-49c3-9d76-1d0eadef4609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2PV-H2D-L_q",
        "outputId": "c2b42c79-95ea-4bb2-c89d-cc458e7cf7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2907, 0.2243, 0.2694, 0.2156],\n",
              "        [0.2658, 0.2114, 0.1947, 0.3280],\n",
              "        [0.1430, 0.4061, 0.2603, 0.1906],\n",
              "        [0.1635, 0.3426, 0.3399, 0.1540]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values, attention = scaled_dot_attention(q, k, v, mask=mask)"
      ],
      "metadata": {
        "id": "pBItZ2c0-PIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL6h6SES-Rs2",
        "outputId": "e6ca9a5e-d773-4d8a-dd06-0d1d5945ec94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5569, 0.4431, 0.0000, 0.0000],\n",
              "        [0.1767, 0.5017, 0.3215, 0.0000],\n",
              "        [0.1635, 0.3426, 0.3399, 0.1540]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcZ2vvQQ-S6u",
        "outputId": "a992659e-ce4e-4109-a921-17e458363e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we are going to concatenate all heads together\n",
        "values = values.reshape(batch_size, sequence_length, num_heads *  head_dim)"
      ],
      "metadata": {
        "id": "8AVv-zj9-kZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjNAN57p-wJ9",
        "outputId": "d4d5b04a-e0d0-42f2-a99b-ac18cd3cd9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FFN over multiheaded\n",
        "linear_layer = nn.Linear(d_model, d_model)"
      ],
      "metadata": {
        "id": "KvcCTPPc-xAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = linear_layer(values)"
      ],
      "metadata": {
        "id": "kR6BqHQa-8uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L78k10us_Air",
        "outputId": "9794d133-2255-426e-ec6a-2610c777403c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now this output from linear layer will be much more context aware !!"
      ],
      "metadata": {
        "id": "WqHBFBCo_GQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class Implementation"
      ],
      "metadata": {
        "id": "TNwmtOyOA8eI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scaled += mask\n",
        "    attention = F.softmax(scaled, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.qkv_layer = nn.Linear(input_dim , 3 * d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, sequence_length, input_dim = x.size()\n",
        "        print(f\"x.size(): {x.size()}\")\n",
        "        qkv = self.qkv_layer(x)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        qkv = qkv.permute(0, 2, 1, 3)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
        "        values, attention = scaled_dot_product(q, k, v, mask)\n",
        "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
        "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
        "        print(f\"values.size(): {values.size()}\")\n",
        "        out = self.linear_layer(values)\n",
        "        print(f\"out.size(): {out.size()}\")\n",
        "        return out"
      ],
      "metadata": {
        "id": "NNi6nqsq_BUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 1024\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "\n",
        "batch_size = 30\n",
        "sequence_length = 5\n",
        "x = torch.randn( (batch_size, sequence_length, input_dim) )\n",
        "\n",
        "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
        "out = model.forward(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amRepR2MBDNg",
        "outputId": "0183291e-07cf-4e51-8f0a-271128be79fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.size(): torch.Size([30, 5, 1024])\n",
            "qkv.size(): torch.Size([30, 5, 1536])\n",
            "qkv.size(): torch.Size([30, 5, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 5, 192])\n",
            "q size: torch.Size([30, 8, 5, 64]), k size: torch.Size([30, 8, 5, 64]), v size: torch.Size([30, 8, 5, 64]), \n",
            "values.size(): torch.Size([30, 8, 5, 64]), attention.size:torch.Size([30, 8, 5, 5]) \n",
            "values.size(): torch.Size([30, 5, 512])\n",
            "out.size(): torch.Size([30, 5, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RZ3Wg5X9BFMp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}