{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Layer Normalization\n",
        "\n",
        "We want to do layer normalization such that in each layer of the neural network the activation vectors are not spare and have mean ~ 0 and sd ~ 1. /\n",
        "\n",
        "Suppose we have 2 word of 3 dimnension\n",
        "\n",
        "X = [[0.2, 0.1, 0.3] , [0.5, 0.1, 0.1]]\n",
        "\n",
        "\n",
        "If we calculate mu11 = 1/3 sum(0.2, 0.1, 0.3) = 0.2\n",
        "\n",
        "and similarly mu21 = 0.233\n",
        "\n",
        "and then,\n",
        "\n",
        "sd11 and s21\n",
        "\n",
        "μ = [mu11, mu22]\n",
        "σ = [sd11, sd21]\n",
        "\n",
        "Then layer normalization output will be γ * [X - μ] / σ + β\n",
        "\n",
        "The output will be learnable params gamma and beta , for every single layer the mean is 0 and sd ~ 1. These values are more tractable and stable during training.\n",
        "\n"
      ],
      "metadata": {
        "id": "zMs5I048fvqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "inputs = torch.Tensor([[[0.2, 0.1, 0.3] , [0.5, 0.1, 0.1]]])\n",
        "B, S, E = inputs.size()\n",
        "inputs = inputs.reshape(S,B, E)\n",
        "inputs.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNtpmXzokuUw",
        "outputId": "241298f3-2050-4125-a36e-b99773e9da9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameter_shape = inputs.size()[-2:]\n",
        "parameter_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IporKDZKlJZi",
        "outputId": "55f83c0a-5f48-40c6-d9e4-997fa327cb29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = nn.Parameter(torch.ones(parameter_shape))\n",
        "beta = nn.Parameter(torch.zeros(parameter_shape))\n",
        "print(gamma.size())\n",
        "print(beta.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOqpERO6lPi9",
        "outputId": "5a585ca0-2bbb-4bd3-8b42-03ce78f053e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3])\n",
            "torch.Size([1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1 due to batch size and 3 as embedding dimensino"
      ],
      "metadata": {
        "id": "sgGatfmKlgtz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBCnW-gfdGru"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNormalization(nn.Module):\n",
        "  def __init__(self, parameters_shape, eps = 1e-5):\n",
        "    super().__init__()\n",
        "    self.parameters_shape = parameters_shape # this determined along which dimension layer normalization is to be applied , here batch and\n",
        "    self.eps = eps # this is to make the division non zero as sd can be zero and it's in division\n",
        "    self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "    self.beta = nn.Parameter(torch.zeros(parameters_shape))\n",
        "\n",
        "  def forward(self, input):\n",
        "    dims = [-(i+1) for i in range(len(self.parameters_shape))] # dimesnion along which we want to peform layer normalization\n",
        "    mean = inputs.mean(dim=dims, keepdim=True) # calculate mean of the inputs for all the words\n",
        "    print(f'Mean \\n ({mean.size()}) : \\n {mean}')\n",
        "    var = ((inputs-mean)**2).mean(dim=dims, keepdim=True)\n",
        "    std = (var + self.eps).sqrt()\n",
        "    print(f'Standard Deviation \\n ({std.size()}) : \\n {std}')\n",
        "    y = (inputs-mean)/std # normalization\n",
        "    print(f\"y \\n ({y.size}) = \\n {y}\")\n",
        "    out = self.gamma *y + self.beta\n",
        "    print(f\"out \\n ({out.size()}) =. \\n {out}\")\n",
        "    return out"
      ],
      "metadata": {
        "id": "DrE-Ce7ZkBB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "sentence_length = 5\n",
        "embedding_dim = 8\n",
        "inputs = torch.randn(sentence_length, batch_size, embedding_dim)"
      ],
      "metadata": {
        "id": "xzL5BCa1pCId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_norm = LayerNormalization(inputs.size()[-2:])\n",
        "layer_norm(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhFCIQbypTbQ",
        "outputId": "3bf6725a-2c3b-45ab-a9ff-397ee0d777af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean \n",
            " (torch.Size([5, 1, 1])) : \n",
            " tensor([[[-0.1311]],\n",
            "\n",
            "        [[ 0.0214]],\n",
            "\n",
            "        [[ 0.1828]],\n",
            "\n",
            "        [[ 0.3760]],\n",
            "\n",
            "        [[-0.2984]]])\n",
            "Standard Deviation \n",
            " (torch.Size([5, 1, 1])) : \n",
            " tensor([[[1.1732]],\n",
            "\n",
            "        [[0.9153]],\n",
            "\n",
            "        [[0.5976]],\n",
            "\n",
            "        [[0.7279]],\n",
            "\n",
            "        [[1.0790]]])\n",
            "y \n",
            " (<built-in method size of Tensor object at 0x7f831db370b0>) = \n",
            " tensor([[[ 1.5343, -1.7197,  0.2753, -1.0941,  1.0343,  0.0885,  0.9377,\n",
            "          -0.2599],\n",
            "         [-0.3968, -0.9933,  1.1634, -1.6930, -1.9114,  0.9607, -1.4323,\n",
            "           0.5926],\n",
            "         [ 1.0643, -0.6483,  0.5650,  0.1134,  0.1231,  0.3545,  0.9177,\n",
            "           0.4241]],\n",
            "\n",
            "        [[-0.2804,  1.5267, -2.7503,  0.1455, -0.6535, -0.2610, -0.1430,\n",
            "          -0.5587],\n",
            "         [-0.3279,  0.4266,  0.7142,  0.4357, -0.5728, -1.1849,  0.3435,\n",
            "           0.4275],\n",
            "         [ 0.1490, -0.9237, -1.1703,  0.8467,  1.5381,  0.9582, -0.5764,\n",
            "           1.8913]],\n",
            "\n",
            "        [[ 0.4463, -0.1295, -0.6628, -2.6863,  0.5283, -1.6540, -0.0169,\n",
            "           0.4133],\n",
            "         [ 1.3373, -0.6678,  0.9884,  0.4277,  0.4927,  1.6403,  0.1338,\n",
            "          -0.4098],\n",
            "         [-0.8659, -1.5626,  0.2583,  1.1116,  0.7670,  0.9787, -0.5128,\n",
            "          -0.3551]],\n",
            "\n",
            "        [[-1.3153,  0.4873, -0.1138, -0.7095, -1.6862,  0.1491,  0.6494,\n",
            "           0.1034],\n",
            "         [ 1.6532,  0.5182,  0.3398,  0.7805,  0.8452,  1.1121,  2.0324,\n",
            "          -0.6675],\n",
            "         [-1.1812, -0.0195, -2.3100,  0.2716, -0.8783,  0.1017,  0.3449,\n",
            "          -0.5076]],\n",
            "\n",
            "        [[ 0.1899, -1.7117, -1.1358, -1.3869,  1.5943,  0.5742,  0.4742,\n",
            "           0.4209],\n",
            "         [ 0.2509, -2.3083,  0.6880, -0.5390, -0.1239,  0.8990, -0.2321,\n",
            "           1.9458],\n",
            "         [-0.3878, -0.7693, -0.4596,  0.6001,  1.2588, -0.0139,  0.7245,\n",
            "          -0.5522]]])\n",
            "out \n",
            " (torch.Size([5, 3, 8])) =. \n",
            " tensor([[[ 1.5343, -1.7197,  0.2753, -1.0941,  1.0343,  0.0885,  0.9377,\n",
            "          -0.2599],\n",
            "         [-0.3968, -0.9933,  1.1634, -1.6930, -1.9114,  0.9607, -1.4323,\n",
            "           0.5926],\n",
            "         [ 1.0643, -0.6483,  0.5650,  0.1134,  0.1231,  0.3545,  0.9177,\n",
            "           0.4241]],\n",
            "\n",
            "        [[-0.2804,  1.5267, -2.7503,  0.1455, -0.6535, -0.2610, -0.1430,\n",
            "          -0.5587],\n",
            "         [-0.3279,  0.4266,  0.7142,  0.4357, -0.5728, -1.1849,  0.3435,\n",
            "           0.4275],\n",
            "         [ 0.1490, -0.9237, -1.1703,  0.8467,  1.5381,  0.9582, -0.5764,\n",
            "           1.8913]],\n",
            "\n",
            "        [[ 0.4463, -0.1295, -0.6628, -2.6863,  0.5283, -1.6540, -0.0169,\n",
            "           0.4133],\n",
            "         [ 1.3373, -0.6678,  0.9884,  0.4277,  0.4927,  1.6403,  0.1338,\n",
            "          -0.4098],\n",
            "         [-0.8659, -1.5626,  0.2583,  1.1116,  0.7670,  0.9787, -0.5128,\n",
            "          -0.3551]],\n",
            "\n",
            "        [[-1.3153,  0.4873, -0.1138, -0.7095, -1.6862,  0.1491,  0.6494,\n",
            "           0.1034],\n",
            "         [ 1.6532,  0.5182,  0.3398,  0.7805,  0.8452,  1.1121,  2.0324,\n",
            "          -0.6675],\n",
            "         [-1.1812, -0.0195, -2.3100,  0.2716, -0.8783,  0.1017,  0.3449,\n",
            "          -0.5076]],\n",
            "\n",
            "        [[ 0.1899, -1.7117, -1.1358, -1.3869,  1.5943,  0.5742,  0.4742,\n",
            "           0.4209],\n",
            "         [ 0.2509, -2.3083,  0.6880, -0.5390, -0.1239,  0.8990, -0.2321,\n",
            "           1.9458],\n",
            "         [-0.3878, -0.7693, -0.4596,  0.6001,  1.2588, -0.0139,  0.7245,\n",
            "          -0.5522]]], grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.5343, -1.7197,  0.2753, -1.0941,  1.0343,  0.0885,  0.9377,\n",
              "          -0.2599],\n",
              "         [-0.3968, -0.9933,  1.1634, -1.6930, -1.9114,  0.9607, -1.4323,\n",
              "           0.5926],\n",
              "         [ 1.0643, -0.6483,  0.5650,  0.1134,  0.1231,  0.3545,  0.9177,\n",
              "           0.4241]],\n",
              "\n",
              "        [[-0.2804,  1.5267, -2.7503,  0.1455, -0.6535, -0.2610, -0.1430,\n",
              "          -0.5587],\n",
              "         [-0.3279,  0.4266,  0.7142,  0.4357, -0.5728, -1.1849,  0.3435,\n",
              "           0.4275],\n",
              "         [ 0.1490, -0.9237, -1.1703,  0.8467,  1.5381,  0.9582, -0.5764,\n",
              "           1.8913]],\n",
              "\n",
              "        [[ 0.4463, -0.1295, -0.6628, -2.6863,  0.5283, -1.6540, -0.0169,\n",
              "           0.4133],\n",
              "         [ 1.3373, -0.6678,  0.9884,  0.4277,  0.4927,  1.6403,  0.1338,\n",
              "          -0.4098],\n",
              "         [-0.8659, -1.5626,  0.2583,  1.1116,  0.7670,  0.9787, -0.5128,\n",
              "          -0.3551]],\n",
              "\n",
              "        [[-1.3153,  0.4873, -0.1138, -0.7095, -1.6862,  0.1491,  0.6494,\n",
              "           0.1034],\n",
              "         [ 1.6532,  0.5182,  0.3398,  0.7805,  0.8452,  1.1121,  2.0324,\n",
              "          -0.6675],\n",
              "         [-1.1812, -0.0195, -2.3100,  0.2716, -0.8783,  0.1017,  0.3449,\n",
              "          -0.5076]],\n",
              "\n",
              "        [[ 0.1899, -1.7117, -1.1358, -1.3869,  1.5943,  0.5742,  0.4742,\n",
              "           0.4209],\n",
              "         [ 0.2509, -2.3083,  0.6880, -0.5390, -0.1239,  0.8990, -0.2321,\n",
              "           1.9458],\n",
              "         [-0.3878, -0.7693, -0.4596,  0.6001,  1.2588, -0.0139,  0.7245,\n",
              "          -0.5522]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mmwUz5InpeE8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}